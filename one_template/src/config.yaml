# cuda
cuda_index: 2
model_name: 'textCNN'

# path
# data_dir: /storage_fast/bbli/sarcasm
data_dir: './data'
dataset_dir: 'stsa'
preprocessed_dir: preprocessed
target_dir: save
bert_path: bert-base-cased 

# path
# bert_path: bert-base-uncased 

emb_dim: 300
output_channels: 100
speaker_emb_dims: 300
project_dims: 300
max_seq_length: 100
batch_size: 16
epoch_size: 10
# train_mode: fine-tuned 
train_mode: random
filters: [3,4,5]
dropout: 0.5

# training
shuffle: True
learning_rate: 1e-3
patience: 100
max_grad_norm: 1.0
warmup_proportion: 0.1
gradient_accumulation_steps: 1
adam_epsilon: 1e-8
warmup_steps: 0
weight_decay: 0.01


pad: '[PAD]'
unk: '[UNK]'
# path
pad: 0
unk: 1
min_freq: 2

# seed
seed: 42
